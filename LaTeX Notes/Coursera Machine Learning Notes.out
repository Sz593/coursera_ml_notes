\BOOKMARK [0][-]{chapter*.2}{Preface}{}% 1
\BOOKMARK [0][-]{chapter.1}{Introduction}{}% 2
\BOOKMARK [1][-]{section.1.1}{Supervised Learning}{chapter.1}% 3
\BOOKMARK [1][-]{section.1.2}{Unsupervised Learning}{chapter.1}% 4
\BOOKMARK [0][-]{chapter.2}{Linear Regression}{}% 5
\BOOKMARK [1][-]{section.2.1}{Univariate Linear Regression}{chapter.2}% 6
\BOOKMARK [2][-]{subsection.2.1.1}{The Hypothesis Function}{section.2.1}% 7
\BOOKMARK [2][-]{subsection.2.1.2}{The Cost Function}{section.2.1}% 8
\BOOKMARK [2][-]{subsection.2.1.3}{Gradient Descent}{section.2.1}% 9
\BOOKMARK [3][-]{subsubsection.2.1.3.1}{Gradient Descent for Linear Regression}{subsection.2.1.3}% 10
\BOOKMARK [1][-]{section.2.2}{Multivariate Linear Regression}{chapter.2}% 11
\BOOKMARK [2][-]{subsection.2.2.1}{Gradient Descent for Multiple Variables}{section.2.2}% 12
\BOOKMARK [2][-]{subsection.2.2.2}{Feature Scaling}{section.2.2}% 13
\BOOKMARK [2][-]{subsection.2.2.3}{Tips for Gradient Descent}{section.2.2}% 14
\BOOKMARK [2][-]{subsection.2.2.4}{Polynomial Regression}{section.2.2}% 15
\BOOKMARK [1][-]{section.2.3}{Vectorized Equations}{chapter.2}% 16
\BOOKMARK [1][-]{section.2.4}{The Normal Equation}{chapter.2}% 17
\BOOKMARK [2][-]{subsection.2.4.1}{Normal Equation Noninvertibility}{section.2.4}% 18
\BOOKMARK [1][-]{section.2.5}{Homework}{chapter.2}% 19
\BOOKMARK [1][-]{section.2.6}{Python Labs: Coding Linear Regression}{chapter.2}% 20
\BOOKMARK [0][-]{chapter.3}{Logistic Regression and Regularization}{}% 21
\BOOKMARK [1][-]{section.3.1}{Binary Classification}{chapter.3}% 22
\BOOKMARK [1][-]{section.3.2}{Hypothesis Representation}{chapter.3}% 23
\BOOKMARK [2][-]{subsection.3.2.1}{Interpretation of the Logistic Hypothesis Function}{section.3.2}% 24
\BOOKMARK [2][-]{subsection.3.2.2}{Fitting Logistic Regression to a Binary Classifier}{section.3.2}% 25
\BOOKMARK [1][-]{section.3.3}{Decision Boundary}{chapter.3}% 26
\BOOKMARK [1][-]{section.3.4}{Cost Function}{chapter.3}% 27
\BOOKMARK [2][-]{subsection.3.4.1}{Simplified Cost Function}{section.3.4}% 28
\BOOKMARK [2][-]{subsection.3.4.2}{Gradient Descent for Logistic Regression}{section.3.4}% 29
\BOOKMARK [1][-]{section.3.5}{Vectorized Equations}{chapter.3}% 30
\BOOKMARK [1][-]{section.3.6}{Advanced Optimization}{chapter.3}% 31
\BOOKMARK [1][-]{section.3.7}{Multiclass Classification: One-vs-All}{chapter.3}% 32
\BOOKMARK [1][-]{section.3.8}{Regularization}{chapter.3}% 33
\BOOKMARK [2][-]{subsection.3.8.1}{Cost Function}{section.3.8}% 34
\BOOKMARK [2][-]{subsection.3.8.2}{Regularized Linear Regression}{section.3.8}% 35
\BOOKMARK [3][-]{subsubsection.3.8.2.1}{Gradient Descent}{subsection.3.8.2}% 36
\BOOKMARK [3][-]{subsubsection.3.8.2.2}{The Normal Equation}{subsection.3.8.2}% 37
\BOOKMARK [2][-]{subsection.3.8.3}{Regularized Logistic Regression}{section.3.8}% 38
\BOOKMARK [1][-]{section.3.9}{Python Labs: Coding Logistic Regression in Python}{chapter.3}% 39
\BOOKMARK [1][-]{section.3.10}{Homework}{chapter.3}% 40
\BOOKMARK [0][-]{chapter.4}{Neural Networks: Representation}{}% 41
\BOOKMARK [1][-]{section.4.1}{Non-linear Hypotheses}{chapter.4}% 42
\BOOKMARK [1][-]{section.4.2}{Neurons and the Brain}{chapter.4}% 43
\BOOKMARK [1][-]{section.4.3}{Model Representation I}{chapter.4}% 44
\BOOKMARK [1][-]{section.4.4}{Model Representation II}{chapter.4}% 45
\BOOKMARK [1][-]{section.4.5}{Examples and Intuitions}{chapter.4}% 46
\BOOKMARK [2][-]{subsection.4.5.1}{Building Logical Gates Using Neural Networks}{section.4.5}% 47
\BOOKMARK [2][-]{subsection.4.5.2}{Logical XNOR Gate}{section.4.5}% 48
\BOOKMARK [1][-]{section.4.6}{Multiclass Classification}{chapter.4}% 49
\BOOKMARK [0][-]{appendix.A}{Notation}{}% 50
\BOOKMARK [0][-]{appendix.B}{Linear Algebra Review}{}% 51
